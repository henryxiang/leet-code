403. Frog Jump | Algorithms | Hard | Dynamic Programming

[TOC]

## Summary

Given a sorted stone array containing the positions at which there are stones in a river. We need to determine whether it is possible or not for a frog to cross the river by stepping over these stones,
provided that the frog starts at position 0, and at every step the frog can make a jump of size $$k-1$$, $$k$$ or $$k+1$$ if the previous jump is of size $$k$$.

## Solution

---
#### Approach #1 Brute Force [Time Limit Exceeded]

In the brute force approach, we make use of a recursive function $$canCross$$ which takes the given stone array, the current position and the current $$jumpsize$$ as input
arguments. We start with $$currentPosition=0$$ and $$jumpsize=0$$. Then for every function call, we start from the $$currentPosition$$ and check if there lies a stone at $$(currentPostion + newjumpsize)$$, where, the
$$newjumpsize$$ could be $$jumpsize$$, $$jumpsize+1$$ or $$jumpsize-1$$. In order to check whether a stone exists at the specified positions, we check the elements of the array in a linear manner.
If a stone exists at any of these positions, we call the recursive function again with the same stone array, the $$currentPosition$$ and
the $$newjumpsize$$ as the parameters. If we are able to reach the end of the stone array through any of these calls, we return $$true$$ to indicate the possibility of reaching the end.




**Complexity Analysis**

* Time complexity : $$O(3^n)$$. Recursion tree can grow upto $$3^n$$.
* Space complexity : $$O(n)$$. Recursion of depth $$n$$ is used.

---
#### Approach #2 Better Brute Force[Time Limit Exceeded]

**Algorithm**

In the previous brute force approach, we need to find if a stone exists at $$(currentPosition + new
jumpsize)$$, where $$newjumpsize$$ could be either of $$jumpsize-1$$, $$jumpsize$$ or
$$jumpsize+1$$. But in order to check if a stone exists at the specified location, we searched the given array in linearly. To optimize this, we can use binary search to look for the element
in the given array since it is sorted. Rest of the method remains the same.



**Complexity Analysis**

* Time complexity : $$O(3^n)$$. Recursion tree can grow upto $$3^n$$.
* Space complexity : $$O(n)$$. Recursion of depth $$n$$ is used.

---
#### Approach #3 Using Memorization [Accepted]

**Algorithm**

Another problem with above approaches is that we can make the same function calls coming through different paths e.g. For a given $$currentIndex$$, we can call the recursive function
$$canCross$$ with the $$jumpsize$$, say $$n$$. This $$n$$ could be resulting from previous $$jumpsize$$ being $$n-1$$,$$n$$ or $$n+1$$. Thus, many redundant function calls could be made
prolonging the running time. This redundancy can be removed by making use of memorization. We make use of a 2-d $$memo$$ array, initialized by $$-1$$s, to store the result returned from a function call for
a particular $$currentIndex$$ and $$jumpsize$$. If the same $$currentIndex$$ and $$jumpsize$$ happens is encountered again, we can return the result directly using the $$memo$$ array. This helps to prune the
search tree to a great extent.


**Complexity Analysis**

* Time complexity : $$O(n^3)$$. Memorization will reduce time complexity to $$O(n^3)$$.

* Space complexity : $$O(n^2)$$. $$memo$$ matrix of size $$n^2$$ is used.

---

#### Approach #4 Using Memorization with Binary Search [Accepted]

**Algorithm**

 We can optimize the above memorization approach, if we make use of Binary Search to find if a stone
exists at $$currentPostion + newjumpsize$$ instead of searching linearly.


**Complexity Analysis**

* Time complexity : $$O\big(n^2 log(n)\big)$$. We traverse the complete $$dp$$ matrix once $$(O(n^2))$$. For every entry we take atmost $$n$$ numbers as pivot.

* Space complexity : $$O(n^2)$$. $$dp$$ matrix of size $$n^2$$ is used.

---

#### Approach #5 Using Dynamic Programming[Accepted]

**Algorithm**

In the DP Approach, we make use of a hashmap $$map$$ which contains $$key:value$$ pairs such that $$key$$ refers to the position at which a stone is present and $$value$$ is a
set containing the $$jumpsize$$ which can lead to the current stone position. We start by making a hashmap whose $$key$$s are all the positions at which a stone is present and the $$value$$s are
all empty except position 0 whose value contains 0. Then, we start traversing the elements(positions) of the given stone array in sequential order. For the $$currentPosition$$, for every possible $$jumpsize$$ in the
$$value$$ set, we check if $$currentPosition + newjumpsize$$ exists in the $$map$$, where $$newjumpsize$$ can be either $$jumpsize-1$$, $$jumpsize$$,
$$jumpsize+1$$. If so, we append the corresponding $$value$$ set with $$newjumpsize$$. We continue in the same manner. If at the end, the $$value$$ set corresponding to the
last position is non-empty, we conclude that reaching the end is possible, otherwise, it isn't.

For more understanding see this animation-


!?!../Documents/403_Frog.json:1000,563!?!



**Complexity Analysis**

* Time complexity : $$O(n^2)$$. Two nested loops are there.

* Space complexity : $$O(n^2)$$. $$hashmap$$ size can grow upto $$n^2$$ .

---

Analysis written by: [@vinod23](https://leetcode.com/vinod23)
